{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccced93a",
   "metadata": {},
   "source": [
    "# Chattbot med RAG-teknik för frågor om Försäkringskassans ersättningar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3879f17e",
   "metadata": {},
   "source": [
    "### Import och konfiguration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64f1994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import unicodedata\n",
    "from pypdf import PdfReader\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7db818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kontroll: ska embeddings byggas om?\n",
    "REBUILD = False      # True = bygg om, False = ladda från fil\n",
    "CHUNK_SIZE = 1000    # Hur många tecken varje chunk får vara\n",
    "K_TOP = 20           # Hur många chunks hämtas vid fråga\n",
    "EMBEDDING_MODEL = \"text-embedding-004\"\n",
    "GENERATION_MODEL = \"gemini-2.0-flash\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda0a21",
   "metadata": {},
   "source": [
    "### Initiera Gemini-klienten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d79365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Startar Gemini-klienten via API-nyckel\n",
    "client = genai.Client(api_key=os.getenv(\"API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c568f6",
   "metadata": {},
   "source": [
    "### Läser in PDF-filer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ea01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Läser in all text från alla PDF-filer i en angiven mapp och slår ihop till en lång textsträng.\n",
    "def read_pdfs_from_folder(folder_path):\n",
    "    all_text = \"\"\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            path = os.path.join(folder_path, filename)\n",
    "            reader = PdfReader(path)\n",
    "            for page in reader.pages:\n",
    "                all_text += page.extract_text()\n",
    "    return all_text\n",
    "\n",
    "# Normaliserar text och tar bort överflödiga mellanslag/radbrytningar.\n",
    "def clean_text(text):\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "# Läser in och förbehandlar all text från PDF-filer i 'data_pdf'-mappen.\n",
    "raw_text = read_pdfs_from_folder(\"data_pdf\")\n",
    "text = clean_text(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e024802",
   "metadata": {},
   "source": [
    "### Chunking \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d354c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delar upp texten i mindre chunks baserat på meningar.\n",
    "sentences = text.split(\". \")\n",
    "chunks = []\n",
    "current_chunk = \"\"\n",
    "\n",
    "for sentence in sentences:\n",
    "    # Lägger till punkt om meningen saknar avslutningstecken.\n",
    "    if not sentence.endswith(\".\") and not sentence.endswith(\"!\") and not sentence.endswith(\"?\"):\n",
    "        sentence += \".\"\n",
    "\n",
    "    # Bygger upp en chunk tills maxlängd nås\n",
    "    if len(current_chunk) + len(sentence) + 1 <= CHUNK_SIZE:\n",
    "        if current_chunk:\n",
    "            current_chunk += \" \" + sentence\n",
    "        else:\n",
    "            current_chunk = sentence\n",
    "    else:\n",
    "        # Spara den nuvarande chunken och börja på en ny.\n",
    "        chunks.append(current_chunk.strip())\n",
    "        current_chunk = sentence\n",
    "\n",
    "# Lägg till sista chunken om det finns något kvar.\n",
    "if current_chunk:\n",
    "    chunks.append(current_chunk.strip())\n",
    "\n",
    "print(f\"Antal chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a5c31c",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar en embedding-vektor för en given textsträng, för att kunna jämföra och söka bland texter semantiskt.\n",
    "def create_embedding(text: str, model=EMBEDDING_MODEL, task_type=\"RETRIEVAL_DOCUMENT\") -> list[float]:\n",
    "    response = client.models.embed_content(\n",
    "        model=model,\n",
    "        contents=text,\n",
    "        config=types.EmbedContentConfig(task_type=task_type)\n",
    "    )\n",
    "    emb = response.embeddings[0].values\n",
    "    v = np.array(emb)\n",
    "    return (v / np.linalg.norm(v)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c938de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laddar embeddings från fil om de finns, annars skapas de och sparas.\n",
    "# Returnerar både chunks och embeddings.\n",
    "def load_or_build_embeddings(chunks: list[str]) -> list[list[float]]:\n",
    "    # Om embeddings redan finns sparade på disk (och REBUILD=False), läs in dem\n",
    "    if not REBUILD and os.path.exists(\"embeddings.parquet\"):\n",
    "        df = pl.read_parquet(\"embeddings.parquet\")\n",
    "        return df[\"texts\"].to_list(), df[\"vectors\"].to_list()\n",
    "    # Annars, skapa embeddings från grunden och spara till fil för framtida bruk\n",
    "    embeddings = [create_embedding(chunk) for chunk in chunks]\n",
    "    df = pl.DataFrame({\"texts\": chunks, \"vectors\": embeddings})\n",
    "    df.write_parquet(\"embeddings.parquet\")\n",
    "    return chunks, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21404832",
   "metadata": {},
   "source": [
    "### VectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8eb720",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStore:\n",
    "    # Klass för att lagra text-chunks och deras embeddings (vektorer) för semantisk sökning med cosine similarity.\n",
    "    def __init__(self, texts=None, vectors=None):\n",
    "        # texts: lista med text-chunks\n",
    "        # vectors: lista med embeddings för respektive text\n",
    "        self.texts = texts if texts is not None else []\n",
    "        self.vectors = [np.array(v) for v in vectors] if vectors is not None else []\n",
    "\n",
    "    def add(self, vector, text):\n",
    "        # Lägger till en embedding-vektor och motsvarande text-chunk\n",
    "        self.vectors.append(np.array(vector))\n",
    "        self.texts.append(text)\n",
    "\n",
    "    def semantic_search(self, query_embedding, k=K_TOP):\n",
    "        # Söker fram de text-chunks som liknar frågan mest enligt semantisk likhet.\n",
    "        similarities = [\n",
    "            (i, np.dot(query_embedding, v) / (np.linalg.norm(query_embedding) * np.linalg.norm(v)))\n",
    "            for i, v in enumerate(self.vectors)\n",
    "        ]\n",
    "        similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "        k = min(k, len(self.texts))\n",
    "        return [self.texts[i] for i, _ in similarities[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skapar ett VectorStore-objekt och fyller det med alla text-chunks och deras embeddings.\n",
    "vs = VectorStore()\n",
    "for chunk, emb in zip(chunks, embeddings):\n",
    "    vs.add(emb, chunk) # Lägger in varje embedding och dess text i VectorStore\n",
    "\n",
    "print(f\"Antal chunks i VectorStore: {len(vs.texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d77375f",
   "metadata": {},
   "source": [
    "### Sökning och prompt till Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa64f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Systemprompt som styr svarsstil och begränsningar\n",
    "system_prompt = \"\"\"\n",
    "Du är expert på socialförsäkringsregler. Svara kortfattat och tydligt på den fråga som ställs och fokusera på det som efterfrågas.\n",
    "Om frågan gäller hur länge man kan få en ersättning, svara i antal dagar om det finns sådan information i källtexten.\n",
    "Om frågan gäller åldersgränser eller andra villkor, nämn dem punktvis om det behövs.\n",
    "Om något är oklart eller saknas i källtexten men frågan gäller socialförsäkringar, skriv: 'Det framgår inte.'\n",
    "Om frågan inte gäller Försäkringskassan eller socialförsäkringar, svara exakt: 'Det vet jag inte.'\n",
    "Hitta inte på egna fakta.\n",
    "\"\"\"\n",
    "# Bygger prompt till modellen: sätter ihop frågan och de mest relevanta textbitarna\n",
    "user_prompt = f\"Fråga: {query}\\n\\nKONTEXT:\\n\" + \"\\n\".join(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7f5fb",
   "metadata": {},
   "source": [
    "### Valideringsdata och utvärderingsprompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Här skapas frågor och förväntade svar som används för automatisk utvärdering av chattbotens prestation.\n",
    "validation_data = [\n",
    "    {\n",
    "        \"question\": \"Vad gäller för sjukpenning för enskild firma?\",\n",
    "        \"ideal_answer\": [\n",
    "            \"Du kan få sjukpenning om du inte kan arbeta på grund av sjukdom och förlorar inkomst. Ersättningen är ca 80 % av din SGI, max 1 250 kr/dag. Du väljer själv karenstid (1, 7, 14, 30, 60 eller 90 dagar). Efter 364 dagar sänks ersättningen till 75 % av SGI. Du måste vara försäkrad i Sverige.\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Vilka får bostadsbidrag?\",\n",
    "        \"ideal_answer\": [\n",
    "            \"Barnfamiljer och unga under 29 år med låg inkomst och tillräcklig boendekostnad kan få bostadsbidrag. Maxbeloppet för unga utan barn är 1 300 kr/månad. Du måste vara folkbokförd där du bor.\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Vad gäller för bostadsbidrag till unga vuxna?\",\n",
    "        \"ideal_answer\": [\n",
    "            \"Unga under 29 år kan få bostadsbidrag om de har låg inkomst och boendekostnaden är tillräckligt hög. Bostadsyta max 60 kvm. Maxbeloppet är 1 300 kr/månad. Bidraget gäller inte inneboende utan barn.\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"När sänks sjukpenningen från 80 till 75 procent?\",\n",
    "        \"ideal_answer\": [\n",
    "            \"Efter 364 dagar sänks sjukpenningen från 80 till 75 procent av SGI. Undantag kan finnas vid allvarlig sjukdom.\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Hur länge kan man få föräldrapenning?\",\n",
    "        \"ideal_answer\": [\n",
    "            \"Föräldrapenning kan tas ut i upp till 480 dagar per barn. 390 dagar är på sjukpenningnivå, 90 dagar på lägstanivå (180 kr/dag). Minst 90 dagar är reserverade för varje förälder.\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Kan jag få bostadsbidrag om jag är inneboende?\",\n",
    "        \"ideal_answer\": [\n",
    "            \"Barnfamiljer kan få bostadsbidrag även som inneboende. Unga utan barn kan inte få bostadsbidrag om de är inneboende.\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Får man sjukpenning om man reser utomlands?\",\n",
    "        \"ideal_answer\": [\n",
    "            \"Du kan behålla sjukpenning vid resa inom EU/EES eller Schweiz utan ansökan. För länder utanför EU/EES/Schweiz måste du ansöka innan resan. Resan får inte försämra din rehabilitering.\"\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Vad är huvudstaden i Tyskland?\",\n",
    "        \"ideal_answer\": [\n",
    "            \"Det vet jag inte.\"\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Systemprompt till modellen för automatisk utvärdering av svaren.\n",
    "evaluation_system_prompt = \"\"\"\n",
    "Du är ett strikt utvärderingssystem. För varje fråga:\n",
    "- Ge 1 poäng om svaret är korrekt och täcker de viktigaste punkterna i något av de godkända svaren, även om det är utförligare eller mer pedagogiskt formulerat.\n",
    "- Ge 0.5 poäng om svaret är delvis korrekt eller missar något väsentligt.\n",
    "- Ge 0 poäng om svaret är felaktigt eller saknar viktiga delar.\n",
    "- Skriv \"Poäng: X\" (X=1, 0.5, 0) på första raden.\n",
    "- Motivera mycket kort på nästa rad.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac82d02",
   "metadata": {},
   "source": [
    "### Utvärdering och resultat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556d196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loopa igenom valideringsfrågorna, generera svar med modellen och utvärdera poäng automatiskt.\n",
    "total_score = 0  # Räknar ut totalpoängen\n",
    "\n",
    "for item in validation_data:\n",
    "    # Plocka ut fråga och idealsvar för aktuell valideringsrunda\n",
    "    query = item[\"question\"]\n",
    "    expected_list = item[\"ideal_answer\"]\n",
    "\n",
    "    # Skapa embedding för frågan och hitta de mest relevanta text-chunks\n",
    "    query_embedding = create_embedding(query)\n",
    "    results = vs.semantic_search(query_embedding, k=K_TOP)\n",
    "    user_prompt = f\"Fråga: {query}\\n\\nKONTEXT:\\n\" + \"\\n\".join(results)\n",
    "\n",
    "    try:\n",
    "        # Generera svar från modellen baserat på sökt kontext och systemprompt\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=types.GenerateContentConfig(system_instruction=system_prompt),\n",
    "            contents=user_prompt\n",
    "        )\n",
    "\n",
    "        # Skapa en utvärderingsprompt där modellen får jämföra sitt eget svar mot idealsvar\n",
    "        evaluation_prompt = (\n",
    "            f\"Fråga: {query}\\n\"\n",
    "            f\"AI-assistentens svar: {response.text}\\n\"\n",
    "            f\"Godkända svar är:\\n- \" + \"\\n- \".join(expected_list)\n",
    "        )\n",
    "\n",
    "        # Modellens svar utvärderas av en särskild utvärderingsprompt (auto-betyg)\n",
    "        evaluation_response = client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash\",\n",
    "            config=types.GenerateContentConfig(system_instruction=evaluation_system_prompt),\n",
    "            contents=evaluation_prompt\n",
    "        )\n",
    "\n",
    "        # Skriv ut fråga, svar och utvärdering för varje test\n",
    "        print(\"\\n--- EVALUERING ---\")\n",
    "        print(f\"Fråga: {query}\")\n",
    "        print(f\"Svar från modellen: {response.text}\")\n",
    "        print(\"Utvärdering:\")\n",
    "        print(evaluation_response.text)\n",
    "\n",
    "        # Extrahera poäng från utvärderingssvaret och summera\n",
    "        for line in evaluation_response.text.split(\"\\n\"):\n",
    "            if \"Poäng:\" in line:\n",
    "                try:\n",
    "                    score = float(line.split(\":\")[-1].strip())\n",
    "                    total_score += score\n",
    "                except Exception as e:\n",
    "                    print(f\"Fel vid poängextraktion: {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Fångar och skriver ut fel som kan uppstå under utvärderingen\n",
    "        print(f\"Fel vid utvärdering av fråga '{query}': {e}\")\n",
    "\n",
    "# Skriv ut totalpoäng efter att alla frågor testats\n",
    "print(f\"\\nTotalpoäng: {total_score} av {len(validation_data)} möjliga\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b8551c",
   "metadata": {},
   "source": [
    "### Reflektion\n",
    "\n",
    "Mitt projekt bygger på erfarenheter från Försäkringskassan, där jag märkt att viktig information på webbplatsen ofta är svår att hitta och förstå. För att göra denna information mer tillgänglig har jag utvecklat en chattbot som besvarar frågor om några vanliga ersättningar.\n",
    "\n",
    "Chattboten använder Retrieval-Augmented Generation (RAG) för att kombinera språkmodellens naturliga språkförståelse med en lokal faktabas baserad på PDF-dokument från Försäkringskassans hemsida. Detta minskar risken för hallucinationer och ökar faktakontrollen.\n",
    "\n",
    "Som exempel fokuserar jag på de tre vanligaste förmånerna: bostadsbidrag, föräldrapenning och sjukpenning. Eftersom det saknas öppna API:er och automatiserad datainsamling kan vara juridiskt och etiskt tveksamt, har jag manuellt samlat in och strukturerat informationen i PDF-format. Lösningen är flexibel och kan vidareutvecklas genom att utöka faktabasen med fler förmåner eller anpassas till andra informationsområden.\n",
    "\n",
    "**Möjligheter (affärsmässiga och praktiska):**\n",
    "- Gör information lättillgänglig och minskar belastning på kundtjänst.\n",
    "- Ger myndigheter och företag möjlighet till kostnadsbesparingar genom automatiserade svar.\n",
    "- Flexibel och återanvändbar lösning som kan anpassas för andra myndigheter, företag eller ämnesområden.\n",
    "- Kan användas även för andra ämnen eller som internt stöd.\n",
    "- Ger snabbare service och ökad tillgänglighet för användarna.\n",
    "\n",
    "**Utmaningar:**\n",
    "- Användare måste förstå att chattboten inte ersätter personlig rådgivning eller handläggare.\n",
    "- Faktabasen måste hållas uppdaterad och korrekt; gamla dokument kan ge felaktiga svar.\n",
    "- Det finns viss risk att svar tolkas som myndighetsbeslut, vilket kan få konsekvenser för användaren.\n",
    "\n",
    "**Förbättringsförslag:**\n",
    "- Utökat stöd för följdfrågor och förbättrad användarupplevelse.\n",
    "- Förbättra gränssnittet med fler visuella element, till exempel tydligare kategorier eller hjälpfunktioner.\n",
    "- Automatiskt hämta och visa länkar från de PDF-dokument som används som faktabas, för bättre källhänvisning.\n",
    "- Vidareutveckla med stöd för fler språk och automatisk uppdatering av faktabasen.\n",
    "\n",
    "**Etik:**\n",
    "-Viktigt att tydligt informera användare om botens begränsningar och att den endast ger vägledande svar.\n",
    "- Boten svarar endast på generella frågor om ersättningar baserat på öppen information.\n",
    "\n",
    "**Sammanfattning:**  \n",
    "En RAG-chattbot är ett kraftfullt verktyg för snabb, faktabaserad kundtjänst och ökad tillgänglighet.  Med fortsatt utveckling och regelbundna uppdateringar har tekniken potential att göra stor samhällsnytta. Det är dock viktigt att tydligt förklara botens begränsningar så att användaren inte missförstår informationen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
